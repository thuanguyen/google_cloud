{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd8c550-f75d-4088-a464-630e8923241c",
   "metadata": {},
   "source": [
    "# **check env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e465ba53-4f5c-431f-b818-fd7cd7ca0142",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /opt/conda\n",
      "jupyterlab               /opt/conda/envs/jupyterlab\n",
      "prolig_0001           *  /opt/conda/envs/prolig_0001\n",
      "pytorch                  /opt/conda/envs/pytorch\n",
      "tensorflow               /opt/conda/envs/tensorflow\n",
      "\n",
      "/home/jupyter/google_cloud/protein_ligand/neuralPlexer\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda env list\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38daf364-1259-4441-84f7-cc86a7ae799b",
   "metadata": {},
   "source": [
    "# **introduction**\n",
    "- [neuralpolexer](https://github.com/zrqiao/NeuralPLexer/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c44fc0-b566-449a-a517-1a0fdc558849",
   "metadata": {},
   "source": [
    "# **running**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e458568-f8d1-4377-bc90-fa82aed3ae9b",
   "metadata": {},
   "source": [
    "## **test - batched_structure_sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64364a0e-649a-4a45-bf54-a24931b1c964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Could not load pretrained MHT weights, skipping\n",
      "Could not load pretrained MHT weights, skipping\n",
      "\n",
      "STDERR: Lightning automatically upgraded your loaded checkpoint from v1.7.0 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt`\n",
      "/opt/conda/envs/prolig_0001/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:251: UserWarning: Found keys that are in the model state dict but not in the checkpoint: ['atnum2vdw_uff', 'plm.embed_tokens.weight', 'plm.layers.0.self_attn.k_proj.weight', 'plm.layers.0.self_attn.k_proj.bias', 'plm.layers.0.self_attn.v_proj.weight', 'plm.layers.0.self_attn.v_proj.bias', 'plm.layers.0.self_attn.q_proj.weight', 'plm.layers.0.self_attn.q_proj.bias', 'plm.layers.0.self_attn.out_proj.weight', 'plm.layers.0.self_attn.out_proj.bias', 'plm.layers.0.self_attn.rot_emb.inv_freq', 'plm.layers.0.self_attn_layer_norm.weight', 'plm.layers.0.self_attn_layer_norm.bias', 'plm.layers.0.fc1.weight', 'plm.layers.0.fc1.bias', 'plm.layers.0.fc2.weight', 'plm.layers.0.fc2.bias', 'plm.layers.0.final_layer_norm.weight', 'plm.layers.0.final_layer_norm.bias', 'plm.layers.1.self_attn.k_proj.weight', 'plm.layers.1.self_attn.k_proj.bias', 'plm.layers.1.self_attn.v_proj.weight', 'plm.layers.1.self_attn.v_proj.bias', 'plm.layers.1.self_attn.q_proj.weight', 'plm.layers.1.self_attn.q_proj.bias', 'plm.layers.1.self_attn.out_proj.weight', 'plm.layers.1.self_attn.out_proj.bias', 'plm.layers.1.self_attn.rot_emb.inv_freq', 'plm.layers.1.self_attn_layer_norm.weight', 'plm.layers.1.self_attn_layer_norm.bias', 'plm.layers.1.fc1.weight', 'plm.layers.1.fc1.bias', 'plm.layers.1.fc2.weight', 'plm.layers.1.fc2.bias', 'plm.layers.1.final_layer_norm.weight', 'plm.layers.1.final_layer_norm.bias', 'plm.layers.2.self_attn.k_proj.weight', 'plm.layers.2.self_attn.k_proj.bias', 'plm.layers.2.self_attn.v_proj.weight', 'plm.layers.2.self_attn.v_proj.bias', 'plm.layers.2.self_attn.q_proj.weight', 'plm.layers.2.self_attn.q_proj.bias', 'plm.layers.2.self_attn.out_proj.weight', 'plm.layers.2.self_attn.out_proj.bias', 'plm.layers.2.self_attn.rot_emb.inv_freq', 'plm.layers.2.self_attn_layer_norm.weight', 'plm.layers.2.self_attn_layer_norm.bias', 'plm.layers.2.fc1.weight', 'plm.layers.2.fc1.bias', 'plm.layers.2.fc2.weight', 'plm.layers.2.fc2.bias', 'plm.layers.2.final_layer_norm.weight', 'plm.layers.2.final_layer_norm.bias', 'plm.layers.3.self_attn.k_proj.weight', 'plm.layers.3.self_attn.k_proj.bias', 'plm.layers.3.self_attn.v_proj.weight', 'plm.layers.3.self_attn.v_proj.bias', 'plm.layers.3.self_attn.q_proj.weight', 'plm.layers.3.self_attn.q_proj.bias', 'plm.layers.3.self_attn.out_proj.weight', 'plm.layers.3.self_attn.out_proj.bias', 'plm.layers.3.self_attn.rot_emb.inv_freq', 'plm.layers.3.self_attn_layer_norm.weight', 'plm.layers.3.self_attn_layer_norm.bias', 'plm.layers.3.fc1.weight', 'plm.layers.3.fc1.bias', 'plm.layers.3.fc2.weight', 'plm.layers.3.fc2.bias', 'plm.layers.3.final_layer_norm.weight', 'plm.layers.3.final_layer_norm.bias', 'plm.layers.4.self_attn.k_proj.weight', 'plm.layers.4.self_attn.k_proj.bias', 'plm.layers.4.self_attn.v_proj.weight', 'plm.layers.4.self_attn.v_proj.bias', 'plm.layers.4.self_attn.q_proj.weight', 'plm.layers.4.self_attn.q_proj.bias', 'plm.layers.4.self_attn.out_proj.weight', 'plm.layers.4.self_attn.out_proj.bias', 'plm.layers.4.self_attn.rot_emb.inv_freq', 'plm.layers.4.self_attn_layer_norm.weight', 'plm.layers.4.self_attn_layer_norm.bias', 'plm.layers.4.fc1.weight', 'plm.layers.4.fc1.bias', 'plm.layers.4.fc2.weight', 'plm.layers.4.fc2.bias', 'plm.layers.4.final_layer_norm.weight', 'plm.layers.4.final_layer_norm.bias', 'plm.layers.5.self_attn.k_proj.weight', 'plm.layers.5.self_attn.k_proj.bias', 'plm.layers.5.self_attn.v_proj.weight', 'plm.layers.5.self_attn.v_proj.bias', 'plm.layers.5.self_attn.q_proj.weight', 'plm.layers.5.self_attn.q_proj.bias', 'plm.layers.5.self_attn.out_proj.weight', 'plm.layers.5.self_attn.out_proj.bias', 'plm.layers.5.self_attn.rot_emb.inv_freq', 'plm.layers.5.self_attn_layer_norm.weight', 'plm.layers.5.self_attn_layer_norm.bias', 'plm.layers.5.fc1.weight', 'plm.layers.5.fc1.bias', 'plm.layers.5.fc2.weight', 'plm.layers.5.fc2.bias', 'plm.layers.5.final_layer_norm.weight', 'plm.layers.5.final_layer_norm.bias', 'plm.layers.6.self_attn.k_proj.weight', 'plm.layers.6.self_attn.k_proj.bias', 'plm.layers.6.self_attn.v_proj.weight', 'plm.layers.6.self_attn.v_proj.bias', 'plm.layers.6.self_attn.q_proj.weight', 'plm.layers.6.self_attn.q_proj.bias', 'plm.layers.6.self_attn.out_proj.weight', 'plm.layers.6.self_attn.out_proj.bias', 'plm.layers.6.self_attn.rot_emb.inv_freq', 'plm.layers.6.self_attn_layer_norm.weight', 'plm.layers.6.self_attn_layer_norm.bias', 'plm.layers.6.fc1.weight', 'plm.layers.6.fc1.bias', 'plm.layers.6.fc2.weight', 'plm.layers.6.fc2.bias', 'plm.layers.6.final_layer_norm.weight', 'plm.layers.6.final_layer_norm.bias', 'plm.layers.7.self_attn.k_proj.weight', 'plm.layers.7.self_attn.k_proj.bias', 'plm.layers.7.self_attn.v_proj.weight', 'plm.layers.7.self_attn.v_proj.bias', 'plm.layers.7.self_attn.q_proj.weight', 'plm.layers.7.self_attn.q_proj.bias', 'plm.layers.7.self_attn.out_proj.weight', 'plm.layers.7.self_attn.out_proj.bias', 'plm.layers.7.self_attn.rot_emb.inv_freq', 'plm.layers.7.self_attn_layer_norm.weight', 'plm.layers.7.self_attn_layer_norm.bias', 'plm.layers.7.fc1.weight', 'plm.layers.7.fc1.bias', 'plm.layers.7.fc2.weight', 'plm.layers.7.fc2.bias', 'plm.layers.7.final_layer_norm.weight', 'plm.layers.7.final_layer_norm.bias', 'plm.layers.8.self_attn.k_proj.weight', 'plm.layers.8.self_attn.k_proj.bias', 'plm.layers.8.self_attn.v_proj.weight', 'plm.layers.8.self_attn.v_proj.bias', 'plm.layers.8.self_attn.q_proj.weight', 'plm.layers.8.self_attn.q_proj.bias', 'plm.layers.8.self_attn.out_proj.weight', 'plm.layers.8.self_attn.out_proj.bias', 'plm.layers.8.self_attn.rot_emb.inv_freq', 'plm.layers.8.self_attn_layer_norm.weight', 'plm.layers.8.self_attn_layer_norm.bias', 'plm.layers.8.fc1.weight', 'plm.layers.8.fc1.bias', 'plm.layers.8.fc2.weight', 'plm.layers.8.fc2.bias', 'plm.layers.8.final_layer_norm.weight', 'plm.layers.8.final_layer_norm.bias', 'plm.layers.9.self_attn.k_proj.weight', 'plm.layers.9.self_attn.k_proj.bias', 'plm.layers.9.self_attn.v_proj.weight', 'plm.layers.9.self_attn.v_proj.bias', 'plm.layers.9.self_attn.q_proj.weight', 'plm.layers.9.self_attn.q_proj.bias', 'plm.layers.9.self_attn.out_proj.weight', 'plm.layers.9.self_attn.out_proj.bias', 'plm.layers.9.self_attn.rot_emb.inv_freq', 'plm.layers.9.self_attn_layer_norm.weight', 'plm.layers.9.self_attn_layer_norm.bias', 'plm.layers.9.fc1.weight', 'plm.layers.9.fc1.bias', 'plm.layers.9.fc2.weight', 'plm.layers.9.fc2.bias', 'plm.layers.9.final_layer_norm.weight', 'plm.layers.9.final_layer_norm.bias', 'plm.layers.10.self_attn.k_proj.weight', 'plm.layers.10.self_attn.k_proj.bias', 'plm.layers.10.self_attn.v_proj.weight', 'plm.layers.10.self_attn.v_proj.bias', 'plm.layers.10.self_attn.q_proj.weight', 'plm.layers.10.self_attn.q_proj.bias', 'plm.layers.10.self_attn.out_proj.weight', 'plm.layers.10.self_attn.out_proj.bias', 'plm.layers.10.self_attn.rot_emb.inv_freq', 'plm.layers.10.self_attn_layer_norm.weight', 'plm.layers.10.self_attn_layer_norm.bias', 'plm.layers.10.fc1.weight', 'plm.layers.10.fc1.bias', 'plm.layers.10.fc2.weight', 'plm.layers.10.fc2.bias', 'plm.layers.10.final_layer_norm.weight', 'plm.layers.10.final_layer_norm.bias', 'plm.layers.11.self_attn.k_proj.weight', 'plm.layers.11.self_attn.k_proj.bias', 'plm.layers.11.self_attn.v_proj.weight', 'plm.layers.11.self_attn.v_proj.bias', 'plm.layers.11.self_attn.q_proj.weight', 'plm.layers.11.self_attn.q_proj.bias', 'plm.layers.11.self_attn.out_proj.weight', 'plm.layers.11.self_attn.out_proj.bias', 'plm.layers.11.self_attn.rot_emb.inv_freq', 'plm.layers.11.self_attn_layer_norm.weight', 'plm.layers.11.self_attn_layer_norm.bias', 'plm.layers.11.fc1.weight', 'plm.layers.11.fc1.bias', 'plm.layers.11.fc2.weight', 'plm.layers.11.fc2.bias', 'plm.layers.11.final_layer_norm.weight', 'plm.layers.11.final_layer_norm.bias', 'plm.layers.12.self_attn.k_proj.weight', 'plm.layers.12.self_attn.k_proj.bias', 'plm.layers.12.self_attn.v_proj.weight', 'plm.layers.12.self_attn.v_proj.bias', 'plm.layers.12.self_attn.q_proj.weight', 'plm.layers.12.self_attn.q_proj.bias', 'plm.layers.12.self_attn.out_proj.weight', 'plm.layers.12.self_attn.out_proj.bias', 'plm.layers.12.self_attn.rot_emb.inv_freq', 'plm.layers.12.self_attn_layer_norm.weight', 'plm.layers.12.self_attn_layer_norm.bias', 'plm.layers.12.fc1.weight', 'plm.layers.12.fc1.bias', 'plm.layers.12.fc2.weight', 'plm.layers.12.fc2.bias', 'plm.layers.12.final_layer_norm.weight', 'plm.layers.12.final_layer_norm.bias', 'plm.layers.13.self_attn.k_proj.weight', 'plm.layers.13.self_attn.k_proj.bias', 'plm.layers.13.self_attn.v_proj.weight', 'plm.layers.13.self_attn.v_proj.bias', 'plm.layers.13.self_attn.q_proj.weight', 'plm.layers.13.self_attn.q_proj.bias', 'plm.layers.13.self_attn.out_proj.weight', 'plm.layers.13.self_attn.out_proj.bias', 'plm.layers.13.self_attn.rot_emb.inv_freq', 'plm.layers.13.self_attn_layer_norm.weight', 'plm.layers.13.self_attn_layer_norm.bias', 'plm.layers.13.fc1.weight', 'plm.layers.13.fc1.bias', 'plm.layers.13.fc2.weight', 'plm.layers.13.fc2.bias', 'plm.layers.13.final_layer_norm.weight', 'plm.layers.13.final_layer_norm.bias', 'plm.layers.14.self_attn.k_proj.weight', 'plm.layers.14.self_attn.k_proj.bias', 'plm.layers.14.self_attn.v_proj.weight', 'plm.layers.14.self_attn.v_proj.bias', 'plm.layers.14.self_attn.q_proj.weight', 'plm.layers.14.self_attn.q_proj.bias', 'plm.layers.14.self_attn.out_proj.weight', 'plm.layers.14.self_attn.out_proj.bias', 'plm.layers.14.self_attn.rot_emb.inv_freq', 'plm.layers.14.self_attn_layer_norm.weight', 'plm.layers.14.self_attn_layer_norm.bias', 'plm.layers.14.fc1.weight', 'plm.layers.14.fc1.bias', 'plm.layers.14.fc2.weight', 'plm.layers.14.fc2.bias', 'plm.layers.14.final_layer_norm.weight', 'plm.layers.14.final_layer_norm.bias', 'plm.layers.15.self_attn.k_proj.weight', 'plm.layers.15.self_attn.k_proj.bias', 'plm.layers.15.self_attn.v_proj.weight', 'plm.layers.15.self_attn.v_proj.bias', 'plm.layers.15.self_attn.q_proj.weight', 'plm.layers.15.self_attn.q_proj.bias', 'plm.layers.15.self_attn.out_proj.weight', 'plm.layers.15.self_attn.out_proj.bias', 'plm.layers.15.self_attn.rot_emb.inv_freq', 'plm.layers.15.self_attn_layer_norm.weight', 'plm.layers.15.self_attn_layer_norm.bias', 'plm.layers.15.fc1.weight', 'plm.layers.15.fc1.bias', 'plm.layers.15.fc2.weight', 'plm.layers.15.fc2.bias', 'plm.layers.15.final_layer_norm.weight', 'plm.layers.15.final_layer_norm.bias', 'plm.layers.16.self_attn.k_proj.weight', 'plm.layers.16.self_attn.k_proj.bias', 'plm.layers.16.self_attn.v_proj.weight', 'plm.layers.16.self_attn.v_proj.bias', 'plm.layers.16.self_attn.q_proj.weight', 'plm.layers.16.self_attn.q_proj.bias', 'plm.layers.16.self_attn.out_proj.weight', 'plm.layers.16.self_attn.out_proj.bias', 'plm.layers.16.self_attn.rot_emb.inv_freq', 'plm.layers.16.self_attn_layer_norm.weight', 'plm.layers.16.self_attn_layer_norm.bias', 'plm.layers.16.fc1.weight', 'plm.layers.16.fc1.bias', 'plm.layers.16.fc2.weight', 'plm.layers.16.fc2.bias', 'plm.layers.16.final_layer_norm.weight', 'plm.layers.16.final_layer_norm.bias', 'plm.layers.17.self_attn.k_proj.weight', 'plm.layers.17.self_attn.k_proj.bias', 'plm.layers.17.self_attn.v_proj.weight', 'plm.layers.17.self_attn.v_proj.bias', 'plm.layers.17.self_attn.q_proj.weight', 'plm.layers.17.self_attn.q_proj.bias', 'plm.layers.17.self_attn.out_proj.weight', 'plm.layers.17.self_attn.out_proj.bias', 'plm.layers.17.self_attn.rot_emb.inv_freq', 'plm.layers.17.self_attn_layer_norm.weight', 'plm.layers.17.self_attn_layer_norm.bias', 'plm.layers.17.fc1.weight', 'plm.layers.17.fc1.bias', 'plm.layers.17.fc2.weight', 'plm.layers.17.fc2.bias', 'plm.layers.17.final_layer_norm.weight', 'plm.layers.17.final_layer_norm.bias', 'plm.layers.18.self_attn.k_proj.weight', 'plm.layers.18.self_attn.k_proj.bias', 'plm.layers.18.self_attn.v_proj.weight', 'plm.layers.18.self_attn.v_proj.bias', 'plm.layers.18.self_attn.q_proj.weight', 'plm.layers.18.self_attn.q_proj.bias', 'plm.layers.18.self_attn.out_proj.weight', 'plm.layers.18.self_attn.out_proj.bias', 'plm.layers.18.self_attn.rot_emb.inv_freq', 'plm.layers.18.self_attn_layer_norm.weight', 'plm.layers.18.self_attn_layer_norm.bias', 'plm.layers.18.fc1.weight', 'plm.layers.18.fc1.bias', 'plm.layers.18.fc2.weight', 'plm.layers.18.fc2.bias', 'plm.layers.18.final_layer_norm.weight', 'plm.layers.18.final_layer_norm.bias', 'plm.layers.19.self_attn.k_proj.weight', 'plm.layers.19.self_attn.k_proj.bias', 'plm.layers.19.self_attn.v_proj.weight', 'plm.layers.19.self_attn.v_proj.bias', 'plm.layers.19.self_attn.q_proj.weight', 'plm.layers.19.self_attn.q_proj.bias', 'plm.layers.19.self_attn.out_proj.weight', 'plm.layers.19.self_attn.out_proj.bias', 'plm.layers.19.self_attn.rot_emb.inv_freq', 'plm.layers.19.self_attn_layer_norm.weight', 'plm.layers.19.self_attn_layer_norm.bias', 'plm.layers.19.fc1.weight', 'plm.layers.19.fc1.bias', 'plm.layers.19.fc2.weight', 'plm.layers.19.fc2.bias', 'plm.layers.19.final_layer_norm.weight', 'plm.layers.19.final_layer_norm.bias', 'plm.layers.20.self_attn.k_proj.weight', 'plm.layers.20.self_attn.k_proj.bias', 'plm.layers.20.self_attn.v_proj.weight', 'plm.layers.20.self_attn.v_proj.bias', 'plm.layers.20.self_attn.q_proj.weight', 'plm.layers.20.self_attn.q_proj.bias', 'plm.layers.20.self_attn.out_proj.weight', 'plm.layers.20.self_attn.out_proj.bias', 'plm.layers.20.self_attn.rot_emb.inv_freq', 'plm.layers.20.self_attn_layer_norm.weight', 'plm.layers.20.self_attn_layer_norm.bias', 'plm.layers.20.fc1.weight', 'plm.layers.20.fc1.bias', 'plm.layers.20.fc2.weight', 'plm.layers.20.fc2.bias', 'plm.layers.20.final_layer_norm.weight', 'plm.layers.20.final_layer_norm.bias', 'plm.layers.21.self_attn.k_proj.weight', 'plm.layers.21.self_attn.k_proj.bias', 'plm.layers.21.self_attn.v_proj.weight', 'plm.layers.21.self_attn.v_proj.bias', 'plm.layers.21.self_attn.q_proj.weight', 'plm.layers.21.self_attn.q_proj.bias', 'plm.layers.21.self_attn.out_proj.weight', 'plm.layers.21.self_attn.out_proj.bias', 'plm.layers.21.self_attn.rot_emb.inv_freq', 'plm.layers.21.self_attn_layer_norm.weight', 'plm.layers.21.self_attn_layer_norm.bias', 'plm.layers.21.fc1.weight', 'plm.layers.21.fc1.bias', 'plm.layers.21.fc2.weight', 'plm.layers.21.fc2.bias', 'plm.layers.21.final_layer_norm.weight', 'plm.layers.21.final_layer_norm.bias', 'plm.layers.22.self_attn.k_proj.weight', 'plm.layers.22.self_attn.k_proj.bias', 'plm.layers.22.self_attn.v_proj.weight', 'plm.layers.22.self_attn.v_proj.bias', 'plm.layers.22.self_attn.q_proj.weight', 'plm.layers.22.self_attn.q_proj.bias', 'plm.layers.22.self_attn.out_proj.weight', 'plm.layers.22.self_attn.out_proj.bias', 'plm.layers.22.self_attn.rot_emb.inv_freq', 'plm.layers.22.self_attn_layer_norm.weight', 'plm.layers.22.self_attn_layer_norm.bias', 'plm.layers.22.fc1.weight', 'plm.layers.22.fc1.bias', 'plm.layers.22.fc2.weight', 'plm.layers.22.fc2.bias', 'plm.layers.22.final_layer_norm.weight', 'plm.layers.22.final_layer_norm.bias', 'plm.layers.23.self_attn.k_proj.weight', 'plm.layers.23.self_attn.k_proj.bias', 'plm.layers.23.self_attn.v_proj.weight', 'plm.layers.23.self_attn.v_proj.bias', 'plm.layers.23.self_attn.q_proj.weight', 'plm.layers.23.self_attn.q_proj.bias', 'plm.layers.23.self_attn.out_proj.weight', 'plm.layers.23.self_attn.out_proj.bias', 'plm.layers.23.self_attn.rot_emb.inv_freq', 'plm.layers.23.self_attn_layer_norm.weight', 'plm.layers.23.self_attn_layer_norm.bias', 'plm.layers.23.fc1.weight', 'plm.layers.23.fc1.bias', 'plm.layers.23.fc2.weight', 'plm.layers.23.fc2.bias', 'plm.layers.23.final_layer_norm.weight', 'plm.layers.23.final_layer_norm.bias', 'plm.layers.24.self_attn.k_proj.weight', 'plm.layers.24.self_attn.k_proj.bias', 'plm.layers.24.self_attn.v_proj.weight', 'plm.layers.24.self_attn.v_proj.bias', 'plm.layers.24.self_attn.q_proj.weight', 'plm.layers.24.self_attn.q_proj.bias', 'plm.layers.24.self_attn.out_proj.weight', 'plm.layers.24.self_attn.out_proj.bias', 'plm.layers.24.self_attn.rot_emb.inv_freq', 'plm.layers.24.self_attn_layer_norm.weight', 'plm.layers.24.self_attn_layer_norm.bias', 'plm.layers.24.fc1.weight', 'plm.layers.24.fc1.bias', 'plm.layers.24.fc2.weight', 'plm.layers.24.fc2.bias', 'plm.layers.24.final_layer_norm.weight', 'plm.layers.24.final_layer_norm.bias', 'plm.layers.25.self_attn.k_proj.weight', 'plm.layers.25.self_attn.k_proj.bias', 'plm.layers.25.self_attn.v_proj.weight', 'plm.layers.25.self_attn.v_proj.bias', 'plm.layers.25.self_attn.q_proj.weight', 'plm.layers.25.self_attn.q_proj.bias', 'plm.layers.25.self_attn.out_proj.weight', 'plm.layers.25.self_attn.out_proj.bias', 'plm.layers.25.self_attn.rot_emb.inv_freq', 'plm.layers.25.self_attn_layer_norm.weight', 'plm.layers.25.self_attn_layer_norm.bias', 'plm.layers.25.fc1.weight', 'plm.layers.25.fc1.bias', 'plm.layers.25.fc2.weight', 'plm.layers.25.fc2.bias', 'plm.layers.25.final_layer_norm.weight', 'plm.layers.25.final_layer_norm.bias', 'plm.layers.26.self_attn.k_proj.weight', 'plm.layers.26.self_attn.k_proj.bias', 'plm.layers.26.self_attn.v_proj.weight', 'plm.layers.26.self_attn.v_proj.bias', 'plm.layers.26.self_attn.q_proj.weight', 'plm.layers.26.self_attn.q_proj.bias', 'plm.layers.26.self_attn.out_proj.weight', 'plm.layers.26.self_attn.out_proj.bias', 'plm.layers.26.self_attn.rot_emb.inv_freq', 'plm.layers.26.self_attn_layer_norm.weight', 'plm.layers.26.self_attn_layer_norm.bias', 'plm.layers.26.fc1.weight', 'plm.layers.26.fc1.bias', 'plm.layers.26.fc2.weight', 'plm.layers.26.fc2.bias', 'plm.layers.26.final_layer_norm.weight', 'plm.layers.26.final_layer_norm.bias', 'plm.layers.27.self_attn.k_proj.weight', 'plm.layers.27.self_attn.k_proj.bias', 'plm.layers.27.self_attn.v_proj.weight', 'plm.layers.27.self_attn.v_proj.bias', 'plm.layers.27.self_attn.q_proj.weight', 'plm.layers.27.self_attn.q_proj.bias', 'plm.layers.27.self_attn.out_proj.weight', 'plm.layers.27.self_attn.out_proj.bias', 'plm.layers.27.self_attn.rot_emb.inv_freq', 'plm.layers.27.self_attn_layer_norm.weight', 'plm.layers.27.self_attn_layer_norm.bias', 'plm.layers.27.fc1.weight', 'plm.layers.27.fc1.bias', 'plm.layers.27.fc2.weight', 'plm.layers.27.fc2.bias', 'plm.layers.27.final_layer_norm.weight', 'plm.layers.27.final_layer_norm.bias', 'plm.layers.28.self_attn.k_proj.weight', 'plm.layers.28.self_attn.k_proj.bias', 'plm.layers.28.self_attn.v_proj.weight', 'plm.layers.28.self_attn.v_proj.bias', 'plm.layers.28.self_attn.q_proj.weight', 'plm.layers.28.self_attn.q_proj.bias', 'plm.layers.28.self_attn.out_proj.weight', 'plm.layers.28.self_attn.out_proj.bias', 'plm.layers.28.self_attn.rot_emb.inv_freq', 'plm.layers.28.self_attn_layer_norm.weight', 'plm.layers.28.self_attn_layer_norm.bias', 'plm.layers.28.fc1.weight', 'plm.layers.28.fc1.bias', 'plm.layers.28.fc2.weight', 'plm.layers.28.fc2.bias', 'plm.layers.28.final_layer_norm.weight', 'plm.layers.28.final_layer_norm.bias', 'plm.layers.29.self_attn.k_proj.weight', 'plm.layers.29.self_attn.k_proj.bias', 'plm.layers.29.self_attn.v_proj.weight', 'plm.layers.29.self_attn.v_proj.bias', 'plm.layers.29.self_attn.q_proj.weight', 'plm.layers.29.self_attn.q_proj.bias', 'plm.layers.29.self_attn.out_proj.weight', 'plm.layers.29.self_attn.out_proj.bias', 'plm.layers.29.self_attn.rot_emb.inv_freq', 'plm.layers.29.self_attn_layer_norm.weight', 'plm.layers.29.self_attn_layer_norm.bias', 'plm.layers.29.fc1.weight', 'plm.layers.29.fc1.bias', 'plm.layers.29.fc2.weight', 'plm.layers.29.fc2.bias', 'plm.layers.29.final_layer_norm.weight', 'plm.layers.29.final_layer_norm.bias', 'plm.layers.30.self_attn.k_proj.weight', 'plm.layers.30.self_attn.k_proj.bias', 'plm.layers.30.self_attn.v_proj.weight', 'plm.layers.30.self_attn.v_proj.bias', 'plm.layers.30.self_attn.q_proj.weight', 'plm.layers.30.self_attn.q_proj.bias', 'plm.layers.30.self_attn.out_proj.weight', 'plm.layers.30.self_attn.out_proj.bias', 'plm.layers.30.self_attn.rot_emb.inv_freq', 'plm.layers.30.self_attn_layer_norm.weight', 'plm.layers.30.self_attn_layer_norm.bias', 'plm.layers.30.fc1.weight', 'plm.layers.30.fc1.bias', 'plm.layers.30.fc2.weight', 'plm.layers.30.fc2.bias', 'plm.layers.30.final_layer_norm.weight', 'plm.layers.30.final_layer_norm.bias', 'plm.layers.31.self_attn.k_proj.weight', 'plm.layers.31.self_attn.k_proj.bias', 'plm.layers.31.self_attn.v_proj.weight', 'plm.layers.31.self_attn.v_proj.bias', 'plm.layers.31.self_attn.q_proj.weight', 'plm.layers.31.self_attn.q_proj.bias', 'plm.layers.31.self_attn.out_proj.weight', 'plm.layers.31.self_attn.out_proj.bias', 'plm.layers.31.self_attn.rot_emb.inv_freq', 'plm.layers.31.self_attn_layer_norm.weight', 'plm.layers.31.self_attn_layer_norm.bias', 'plm.layers.31.fc1.weight', 'plm.layers.31.fc1.bias', 'plm.layers.31.fc2.weight', 'plm.layers.31.fc2.bias', 'plm.layers.31.final_layer_norm.weight', 'plm.layers.31.final_layer_norm.bias', 'plm.layers.32.self_attn.k_proj.weight', 'plm.layers.32.self_attn.k_proj.bias', 'plm.layers.32.self_attn.v_proj.weight', 'plm.layers.32.self_attn.v_proj.bias', 'plm.layers.32.self_attn.q_proj.weight', 'plm.layers.32.self_attn.q_proj.bias', 'plm.layers.32.self_attn.out_proj.weight', 'plm.layers.32.self_attn.out_proj.bias', 'plm.layers.32.self_attn.rot_emb.inv_freq', 'plm.layers.32.self_attn_layer_norm.weight', 'plm.layers.32.self_attn_layer_norm.bias', 'plm.layers.32.fc1.weight', 'plm.layers.32.fc1.bias', 'plm.layers.32.fc2.weight', 'plm.layers.32.fc2.bias', 'plm.layers.32.final_layer_norm.weight', 'plm.layers.32.final_layer_norm.bias', 'plm.contact_head.regression.weight', 'plm.contact_head.regression.bias', 'plm.emb_layer_norm_after.weight', 'plm.emb_layer_norm_after.bias', 'plm.lm_head.weight', 'plm.lm_head.bias', 'plm.lm_head.dense.weight', 'plm.lm_head.dense.bias', 'plm.lm_head.layer_norm.weight', 'plm.lm_head.layer_norm.bias', 'protein_encoder.template_binding_site_enc.weight', 'pl_contact_stack.template_binding_site_enc.weight']\n",
      "  rank_zero_warn(\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.7.0 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt`\n",
      "/opt/conda/envs/prolig_0001/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:251: UserWarning: Found keys that are in the model state dict but not in the checkpoint: ['atnum2vdw_uff', 'plm.embed_tokens.weight', 'plm.layers.0.self_attn.k_proj.weight', 'plm.layers.0.self_attn.k_proj.bias', 'plm.layers.0.self_attn.v_proj.weight', 'plm.layers.0.self_attn.v_proj.bias', 'plm.layers.0.self_attn.q_proj.weight', 'plm.layers.0.self_attn.q_proj.bias', 'plm.layers.0.self_attn.out_proj.weight', 'plm.layers.0.self_attn.out_proj.bias', 'plm.layers.0.self_attn.rot_emb.inv_freq', 'plm.layers.0.self_attn_layer_norm.weight', 'plm.layers.0.self_attn_layer_norm.bias', 'plm.layers.0.fc1.weight', 'plm.layers.0.fc1.bias', 'plm.layers.0.fc2.weight', 'plm.layers.0.fc2.bias', 'plm.layers.0.final_layer_norm.weight', 'plm.layers.0.final_layer_norm.bias', 'plm.layers.1.self_attn.k_proj.weight', 'plm.layers.1.self_attn.k_proj.bias', 'plm.layers.1.self_attn.v_proj.weight', 'plm.layers.1.self_attn.v_proj.bias', 'plm.layers.1.self_attn.q_proj.weight', 'plm.layers.1.self_attn.q_proj.bias', 'plm.layers.1.self_attn.out_proj.weight', 'plm.layers.1.self_attn.out_proj.bias', 'plm.layers.1.self_attn.rot_emb.inv_freq', 'plm.layers.1.self_attn_layer_norm.weight', 'plm.layers.1.self_attn_layer_norm.bias', 'plm.layers.1.fc1.weight', 'plm.layers.1.fc1.bias', 'plm.layers.1.fc2.weight', 'plm.layers.1.fc2.bias', 'plm.layers.1.final_layer_norm.weight', 'plm.layers.1.final_layer_norm.bias', 'plm.layers.2.self_attn.k_proj.weight', 'plm.layers.2.self_attn.k_proj.bias', 'plm.layers.2.self_attn.v_proj.weight', 'plm.layers.2.self_attn.v_proj.bias', 'plm.layers.2.self_attn.q_proj.weight', 'plm.layers.2.self_attn.q_proj.bias', 'plm.layers.2.self_attn.out_proj.weight', 'plm.layers.2.self_attn.out_proj.bias', 'plm.layers.2.self_attn.rot_emb.inv_freq', 'plm.layers.2.self_attn_layer_norm.weight', 'plm.layers.2.self_attn_layer_norm.bias', 'plm.layers.2.fc1.weight', 'plm.layers.2.fc1.bias', 'plm.layers.2.fc2.weight', 'plm.layers.2.fc2.bias', 'plm.layers.2.final_layer_norm.weight', 'plm.layers.2.final_layer_norm.bias', 'plm.layers.3.self_attn.k_proj.weight', 'plm.layers.3.self_attn.k_proj.bias', 'plm.layers.3.self_attn.v_proj.weight', 'plm.layers.3.self_attn.v_proj.bias', 'plm.layers.3.self_attn.q_proj.weight', 'plm.layers.3.self_attn.q_proj.bias', 'plm.layers.3.self_attn.out_proj.weight', 'plm.layers.3.self_attn.out_proj.bias', 'plm.layers.3.self_attn.rot_emb.inv_freq', 'plm.layers.3.self_attn_layer_norm.weight', 'plm.layers.3.self_attn_layer_norm.bias', 'plm.layers.3.fc1.weight', 'plm.layers.3.fc1.bias', 'plm.layers.3.fc2.weight', 'plm.layers.3.fc2.bias', 'plm.layers.3.final_layer_norm.weight', 'plm.layers.3.final_layer_norm.bias', 'plm.layers.4.self_attn.k_proj.weight', 'plm.layers.4.self_attn.k_proj.bias', 'plm.layers.4.self_attn.v_proj.weight', 'plm.layers.4.self_attn.v_proj.bias', 'plm.layers.4.self_attn.q_proj.weight', 'plm.layers.4.self_attn.q_proj.bias', 'plm.layers.4.self_attn.out_proj.weight', 'plm.layers.4.self_attn.out_proj.bias', 'plm.layers.4.self_attn.rot_emb.inv_freq', 'plm.layers.4.self_attn_layer_norm.weight', 'plm.layers.4.self_attn_layer_norm.bias', 'plm.layers.4.fc1.weight', 'plm.layers.4.fc1.bias', 'plm.layers.4.fc2.weight', 'plm.layers.4.fc2.bias', 'plm.layers.4.final_layer_norm.weight', 'plm.layers.4.final_layer_norm.bias', 'plm.layers.5.self_attn.k_proj.weight', 'plm.layers.5.self_attn.k_proj.bias', 'plm.layers.5.self_attn.v_proj.weight', 'plm.layers.5.self_attn.v_proj.bias', 'plm.layers.5.self_attn.q_proj.weight', 'plm.layers.5.self_attn.q_proj.bias', 'plm.layers.5.self_attn.out_proj.weight', 'plm.layers.5.self_attn.out_proj.bias', 'plm.layers.5.self_attn.rot_emb.inv_freq', 'plm.layers.5.self_attn_layer_norm.weight', 'plm.layers.5.self_attn_layer_norm.bias', 'plm.layers.5.fc1.weight', 'plm.layers.5.fc1.bias', 'plm.layers.5.fc2.weight', 'plm.layers.5.fc2.bias', 'plm.layers.5.final_layer_norm.weight', 'plm.layers.5.final_layer_norm.bias', 'plm.layers.6.self_attn.k_proj.weight', 'plm.layers.6.self_attn.k_proj.bias', 'plm.layers.6.self_attn.v_proj.weight', 'plm.layers.6.self_attn.v_proj.bias', 'plm.layers.6.self_attn.q_proj.weight', 'plm.layers.6.self_attn.q_proj.bias', 'plm.layers.6.self_attn.out_proj.weight', 'plm.layers.6.self_attn.out_proj.bias', 'plm.layers.6.self_attn.rot_emb.inv_freq', 'plm.layers.6.self_attn_layer_norm.weight', 'plm.layers.6.self_attn_layer_norm.bias', 'plm.layers.6.fc1.weight', 'plm.layers.6.fc1.bias', 'plm.layers.6.fc2.weight', 'plm.layers.6.fc2.bias', 'plm.layers.6.final_layer_norm.weight', 'plm.layers.6.final_layer_norm.bias', 'plm.layers.7.self_attn.k_proj.weight', 'plm.layers.7.self_attn.k_proj.bias', 'plm.layers.7.self_attn.v_proj.weight', 'plm.layers.7.self_attn.v_proj.bias', 'plm.layers.7.self_attn.q_proj.weight', 'plm.layers.7.self_attn.q_proj.bias', 'plm.layers.7.self_attn.out_proj.weight', 'plm.layers.7.self_attn.out_proj.bias', 'plm.layers.7.self_attn.rot_emb.inv_freq', 'plm.layers.7.self_attn_layer_norm.weight', 'plm.layers.7.self_attn_layer_norm.bias', 'plm.layers.7.fc1.weight', 'plm.layers.7.fc1.bias', 'plm.layers.7.fc2.weight', 'plm.layers.7.fc2.bias', 'plm.layers.7.final_layer_norm.weight', 'plm.layers.7.final_layer_norm.bias', 'plm.layers.8.self_attn.k_proj.weight', 'plm.layers.8.self_attn.k_proj.bias', 'plm.layers.8.self_attn.v_proj.weight', 'plm.layers.8.self_attn.v_proj.bias', 'plm.layers.8.self_attn.q_proj.weight', 'plm.layers.8.self_attn.q_proj.bias', 'plm.layers.8.self_attn.out_proj.weight', 'plm.layers.8.self_attn.out_proj.bias', 'plm.layers.8.self_attn.rot_emb.inv_freq', 'plm.layers.8.self_attn_layer_norm.weight', 'plm.layers.8.self_attn_layer_norm.bias', 'plm.layers.8.fc1.weight', 'plm.layers.8.fc1.bias', 'plm.layers.8.fc2.weight', 'plm.layers.8.fc2.bias', 'plm.layers.8.final_layer_norm.weight', 'plm.layers.8.final_layer_norm.bias', 'plm.layers.9.self_attn.k_proj.weight', 'plm.layers.9.self_attn.k_proj.bias', 'plm.layers.9.self_attn.v_proj.weight', 'plm.layers.9.self_attn.v_proj.bias', 'plm.layers.9.self_attn.q_proj.weight', 'plm.layers.9.self_attn.q_proj.bias', 'plm.layers.9.self_attn.out_proj.weight', 'plm.layers.9.self_attn.out_proj.bias', 'plm.layers.9.self_attn.rot_emb.inv_freq', 'plm.layers.9.self_attn_layer_norm.weight', 'plm.layers.9.self_attn_layer_norm.bias', 'plm.layers.9.fc1.weight', 'plm.layers.9.fc1.bias', 'plm.layers.9.fc2.weight', 'plm.layers.9.fc2.bias', 'plm.layers.9.final_layer_norm.weight', 'plm.layers.9.final_layer_norm.bias', 'plm.layers.10.self_attn.k_proj.weight', 'plm.layers.10.self_attn.k_proj.bias', 'plm.layers.10.self_attn.v_proj.weight', 'plm.layers.10.self_attn.v_proj.bias', 'plm.layers.10.self_attn.q_proj.weight', 'plm.layers.10.self_attn.q_proj.bias', 'plm.layers.10.self_attn.out_proj.weight', 'plm.layers.10.self_attn.out_proj.bias', 'plm.layers.10.self_attn.rot_emb.inv_freq', 'plm.layers.10.self_attn_layer_norm.weight', 'plm.layers.10.self_attn_layer_norm.bias', 'plm.layers.10.fc1.weight', 'plm.layers.10.fc1.bias', 'plm.layers.10.fc2.weight', 'plm.layers.10.fc2.bias', 'plm.layers.10.final_layer_norm.weight', 'plm.layers.10.final_layer_norm.bias', 'plm.layers.11.self_attn.k_proj.weight', 'plm.layers.11.self_attn.k_proj.bias', 'plm.layers.11.self_attn.v_proj.weight', 'plm.layers.11.self_attn.v_proj.bias', 'plm.layers.11.self_attn.q_proj.weight', 'plm.layers.11.self_attn.q_proj.bias', 'plm.layers.11.self_attn.out_proj.weight', 'plm.layers.11.self_attn.out_proj.bias', 'plm.layers.11.self_attn.rot_emb.inv_freq', 'plm.layers.11.self_attn_layer_norm.weight', 'plm.layers.11.self_attn_layer_norm.bias', 'plm.layers.11.fc1.weight', 'plm.layers.11.fc1.bias', 'plm.layers.11.fc2.weight', 'plm.layers.11.fc2.bias', 'plm.layers.11.final_layer_norm.weight', 'plm.layers.11.final_layer_norm.bias', 'plm.layers.12.self_attn.k_proj.weight', 'plm.layers.12.self_attn.k_proj.bias', 'plm.layers.12.self_attn.v_proj.weight', 'plm.layers.12.self_attn.v_proj.bias', 'plm.layers.12.self_attn.q_proj.weight', 'plm.layers.12.self_attn.q_proj.bias', 'plm.layers.12.self_attn.out_proj.weight', 'plm.layers.12.self_attn.out_proj.bias', 'plm.layers.12.self_attn.rot_emb.inv_freq', 'plm.layers.12.self_attn_layer_norm.weight', 'plm.layers.12.self_attn_layer_norm.bias', 'plm.layers.12.fc1.weight', 'plm.layers.12.fc1.bias', 'plm.layers.12.fc2.weight', 'plm.layers.12.fc2.bias', 'plm.layers.12.final_layer_norm.weight', 'plm.layers.12.final_layer_norm.bias', 'plm.layers.13.self_attn.k_proj.weight', 'plm.layers.13.self_attn.k_proj.bias', 'plm.layers.13.self_attn.v_proj.weight', 'plm.layers.13.self_attn.v_proj.bias', 'plm.layers.13.self_attn.q_proj.weight', 'plm.layers.13.self_attn.q_proj.bias', 'plm.layers.13.self_attn.out_proj.weight', 'plm.layers.13.self_attn.out_proj.bias', 'plm.layers.13.self_attn.rot_emb.inv_freq', 'plm.layers.13.self_attn_layer_norm.weight', 'plm.layers.13.self_attn_layer_norm.bias', 'plm.layers.13.fc1.weight', 'plm.layers.13.fc1.bias', 'plm.layers.13.fc2.weight', 'plm.layers.13.fc2.bias', 'plm.layers.13.final_layer_norm.weight', 'plm.layers.13.final_layer_norm.bias', 'plm.layers.14.self_attn.k_proj.weight', 'plm.layers.14.self_attn.k_proj.bias', 'plm.layers.14.self_attn.v_proj.weight', 'plm.layers.14.self_attn.v_proj.bias', 'plm.layers.14.self_attn.q_proj.weight', 'plm.layers.14.self_attn.q_proj.bias', 'plm.layers.14.self_attn.out_proj.weight', 'plm.layers.14.self_attn.out_proj.bias', 'plm.layers.14.self_attn.rot_emb.inv_freq', 'plm.layers.14.self_attn_layer_norm.weight', 'plm.layers.14.self_attn_layer_norm.bias', 'plm.layers.14.fc1.weight', 'plm.layers.14.fc1.bias', 'plm.layers.14.fc2.weight', 'plm.layers.14.fc2.bias', 'plm.layers.14.final_layer_norm.weight', 'plm.layers.14.final_layer_norm.bias', 'plm.layers.15.self_attn.k_proj.weight', 'plm.layers.15.self_attn.k_proj.bias', 'plm.layers.15.self_attn.v_proj.weight', 'plm.layers.15.self_attn.v_proj.bias', 'plm.layers.15.self_attn.q_proj.weight', 'plm.layers.15.self_attn.q_proj.bias', 'plm.layers.15.self_attn.out_proj.weight', 'plm.layers.15.self_attn.out_proj.bias', 'plm.layers.15.self_attn.rot_emb.inv_freq', 'plm.layers.15.self_attn_layer_norm.weight', 'plm.layers.15.self_attn_layer_norm.bias', 'plm.layers.15.fc1.weight', 'plm.layers.15.fc1.bias', 'plm.layers.15.fc2.weight', 'plm.layers.15.fc2.bias', 'plm.layers.15.final_layer_norm.weight', 'plm.layers.15.final_layer_norm.bias', 'plm.layers.16.self_attn.k_proj.weight', 'plm.layers.16.self_attn.k_proj.bias', 'plm.layers.16.self_attn.v_proj.weight', 'plm.layers.16.self_attn.v_proj.bias', 'plm.layers.16.self_attn.q_proj.weight', 'plm.layers.16.self_attn.q_proj.bias', 'plm.layers.16.self_attn.out_proj.weight', 'plm.layers.16.self_attn.out_proj.bias', 'plm.layers.16.self_attn.rot_emb.inv_freq', 'plm.layers.16.self_attn_layer_norm.weight', 'plm.layers.16.self_attn_layer_norm.bias', 'plm.layers.16.fc1.weight', 'plm.layers.16.fc1.bias', 'plm.layers.16.fc2.weight', 'plm.layers.16.fc2.bias', 'plm.layers.16.final_layer_norm.weight', 'plm.layers.16.final_layer_norm.bias', 'plm.layers.17.self_attn.k_proj.weight', 'plm.layers.17.self_attn.k_proj.bias', 'plm.layers.17.self_attn.v_proj.weight', 'plm.layers.17.self_attn.v_proj.bias', 'plm.layers.17.self_attn.q_proj.weight', 'plm.layers.17.self_attn.q_proj.bias', 'plm.layers.17.self_attn.out_proj.weight', 'plm.layers.17.self_attn.out_proj.bias', 'plm.layers.17.self_attn.rot_emb.inv_freq', 'plm.layers.17.self_attn_layer_norm.weight', 'plm.layers.17.self_attn_layer_norm.bias', 'plm.layers.17.fc1.weight', 'plm.layers.17.fc1.bias', 'plm.layers.17.fc2.weight', 'plm.layers.17.fc2.bias', 'plm.layers.17.final_layer_norm.weight', 'plm.layers.17.final_layer_norm.bias', 'plm.layers.18.self_attn.k_proj.weight', 'plm.layers.18.self_attn.k_proj.bias', 'plm.layers.18.self_attn.v_proj.weight', 'plm.layers.18.self_attn.v_proj.bias', 'plm.layers.18.self_attn.q_proj.weight', 'plm.layers.18.self_attn.q_proj.bias', 'plm.layers.18.self_attn.out_proj.weight', 'plm.layers.18.self_attn.out_proj.bias', 'plm.layers.18.self_attn.rot_emb.inv_freq', 'plm.layers.18.self_attn_layer_norm.weight', 'plm.layers.18.self_attn_layer_norm.bias', 'plm.layers.18.fc1.weight', 'plm.layers.18.fc1.bias', 'plm.layers.18.fc2.weight', 'plm.layers.18.fc2.bias', 'plm.layers.18.final_layer_norm.weight', 'plm.layers.18.final_layer_norm.bias', 'plm.layers.19.self_attn.k_proj.weight', 'plm.layers.19.self_attn.k_proj.bias', 'plm.layers.19.self_attn.v_proj.weight', 'plm.layers.19.self_attn.v_proj.bias', 'plm.layers.19.self_attn.q_proj.weight', 'plm.layers.19.self_attn.q_proj.bias', 'plm.layers.19.self_attn.out_proj.weight', 'plm.layers.19.self_attn.out_proj.bias', 'plm.layers.19.self_attn.rot_emb.inv_freq', 'plm.layers.19.self_attn_layer_norm.weight', 'plm.layers.19.self_attn_layer_norm.bias', 'plm.layers.19.fc1.weight', 'plm.layers.19.fc1.bias', 'plm.layers.19.fc2.weight', 'plm.layers.19.fc2.bias', 'plm.layers.19.final_layer_norm.weight', 'plm.layers.19.final_layer_norm.bias', 'plm.layers.20.self_attn.k_proj.weight', 'plm.layers.20.self_attn.k_proj.bias', 'plm.layers.20.self_attn.v_proj.weight', 'plm.layers.20.self_attn.v_proj.bias', 'plm.layers.20.self_attn.q_proj.weight', 'plm.layers.20.self_attn.q_proj.bias', 'plm.layers.20.self_attn.out_proj.weight', 'plm.layers.20.self_attn.out_proj.bias', 'plm.layers.20.self_attn.rot_emb.inv_freq', 'plm.layers.20.self_attn_layer_norm.weight', 'plm.layers.20.self_attn_layer_norm.bias', 'plm.layers.20.fc1.weight', 'plm.layers.20.fc1.bias', 'plm.layers.20.fc2.weight', 'plm.layers.20.fc2.bias', 'plm.layers.20.final_layer_norm.weight', 'plm.layers.20.final_layer_norm.bias', 'plm.layers.21.self_attn.k_proj.weight', 'plm.layers.21.self_attn.k_proj.bias', 'plm.layers.21.self_attn.v_proj.weight', 'plm.layers.21.self_attn.v_proj.bias', 'plm.layers.21.self_attn.q_proj.weight', 'plm.layers.21.self_attn.q_proj.bias', 'plm.layers.21.self_attn.out_proj.weight', 'plm.layers.21.self_attn.out_proj.bias', 'plm.layers.21.self_attn.rot_emb.inv_freq', 'plm.layers.21.self_attn_layer_norm.weight', 'plm.layers.21.self_attn_layer_norm.bias', 'plm.layers.21.fc1.weight', 'plm.layers.21.fc1.bias', 'plm.layers.21.fc2.weight', 'plm.layers.21.fc2.bias', 'plm.layers.21.final_layer_norm.weight', 'plm.layers.21.final_layer_norm.bias', 'plm.layers.22.self_attn.k_proj.weight', 'plm.layers.22.self_attn.k_proj.bias', 'plm.layers.22.self_attn.v_proj.weight', 'plm.layers.22.self_attn.v_proj.bias', 'plm.layers.22.self_attn.q_proj.weight', 'plm.layers.22.self_attn.q_proj.bias', 'plm.layers.22.self_attn.out_proj.weight', 'plm.layers.22.self_attn.out_proj.bias', 'plm.layers.22.self_attn.rot_emb.inv_freq', 'plm.layers.22.self_attn_layer_norm.weight', 'plm.layers.22.self_attn_layer_norm.bias', 'plm.layers.22.fc1.weight', 'plm.layers.22.fc1.bias', 'plm.layers.22.fc2.weight', 'plm.layers.22.fc2.bias', 'plm.layers.22.final_layer_norm.weight', 'plm.layers.22.final_layer_norm.bias', 'plm.layers.23.self_attn.k_proj.weight', 'plm.layers.23.self_attn.k_proj.bias', 'plm.layers.23.self_attn.v_proj.weight', 'plm.layers.23.self_attn.v_proj.bias', 'plm.layers.23.self_attn.q_proj.weight', 'plm.layers.23.self_attn.q_proj.bias', 'plm.layers.23.self_attn.out_proj.weight', 'plm.layers.23.self_attn.out_proj.bias', 'plm.layers.23.self_attn.rot_emb.inv_freq', 'plm.layers.23.self_attn_layer_norm.weight', 'plm.layers.23.self_attn_layer_norm.bias', 'plm.layers.23.fc1.weight', 'plm.layers.23.fc1.bias', 'plm.layers.23.fc2.weight', 'plm.layers.23.fc2.bias', 'plm.layers.23.final_layer_norm.weight', 'plm.layers.23.final_layer_norm.bias', 'plm.layers.24.self_attn.k_proj.weight', 'plm.layers.24.self_attn.k_proj.bias', 'plm.layers.24.self_attn.v_proj.weight', 'plm.layers.24.self_attn.v_proj.bias', 'plm.layers.24.self_attn.q_proj.weight', 'plm.layers.24.self_attn.q_proj.bias', 'plm.layers.24.self_attn.out_proj.weight', 'plm.layers.24.self_attn.out_proj.bias', 'plm.layers.24.self_attn.rot_emb.inv_freq', 'plm.layers.24.self_attn_layer_norm.weight', 'plm.layers.24.self_attn_layer_norm.bias', 'plm.layers.24.fc1.weight', 'plm.layers.24.fc1.bias', 'plm.layers.24.fc2.weight', 'plm.layers.24.fc2.bias', 'plm.layers.24.final_layer_norm.weight', 'plm.layers.24.final_layer_norm.bias', 'plm.layers.25.self_attn.k_proj.weight', 'plm.layers.25.self_attn.k_proj.bias', 'plm.layers.25.self_attn.v_proj.weight', 'plm.layers.25.self_attn.v_proj.bias', 'plm.layers.25.self_attn.q_proj.weight', 'plm.layers.25.self_attn.q_proj.bias', 'plm.layers.25.self_attn.out_proj.weight', 'plm.layers.25.self_attn.out_proj.bias', 'plm.layers.25.self_attn.rot_emb.inv_freq', 'plm.layers.25.self_attn_layer_norm.weight', 'plm.layers.25.self_attn_layer_norm.bias', 'plm.layers.25.fc1.weight', 'plm.layers.25.fc1.bias', 'plm.layers.25.fc2.weight', 'plm.layers.25.fc2.bias', 'plm.layers.25.final_layer_norm.weight', 'plm.layers.25.final_layer_norm.bias', 'plm.layers.26.self_attn.k_proj.weight', 'plm.layers.26.self_attn.k_proj.bias', 'plm.layers.26.self_attn.v_proj.weight', 'plm.layers.26.self_attn.v_proj.bias', 'plm.layers.26.self_attn.q_proj.weight', 'plm.layers.26.self_attn.q_proj.bias', 'plm.layers.26.self_attn.out_proj.weight', 'plm.layers.26.self_attn.out_proj.bias', 'plm.layers.26.self_attn.rot_emb.inv_freq', 'plm.layers.26.self_attn_layer_norm.weight', 'plm.layers.26.self_attn_layer_norm.bias', 'plm.layers.26.fc1.weight', 'plm.layers.26.fc1.bias', 'plm.layers.26.fc2.weight', 'plm.layers.26.fc2.bias', 'plm.layers.26.final_layer_norm.weight', 'plm.layers.26.final_layer_norm.bias', 'plm.layers.27.self_attn.k_proj.weight', 'plm.layers.27.self_attn.k_proj.bias', 'plm.layers.27.self_attn.v_proj.weight', 'plm.layers.27.self_attn.v_proj.bias', 'plm.layers.27.self_attn.q_proj.weight', 'plm.layers.27.self_attn.q_proj.bias', 'plm.layers.27.self_attn.out_proj.weight', 'plm.layers.27.self_attn.out_proj.bias', 'plm.layers.27.self_attn.rot_emb.inv_freq', 'plm.layers.27.self_attn_layer_norm.weight', 'plm.layers.27.self_attn_layer_norm.bias', 'plm.layers.27.fc1.weight', 'plm.layers.27.fc1.bias', 'plm.layers.27.fc2.weight', 'plm.layers.27.fc2.bias', 'plm.layers.27.final_layer_norm.weight', 'plm.layers.27.final_layer_norm.bias', 'plm.layers.28.self_attn.k_proj.weight', 'plm.layers.28.self_attn.k_proj.bias', 'plm.layers.28.self_attn.v_proj.weight', 'plm.layers.28.self_attn.v_proj.bias', 'plm.layers.28.self_attn.q_proj.weight', 'plm.layers.28.self_attn.q_proj.bias', 'plm.layers.28.self_attn.out_proj.weight', 'plm.layers.28.self_attn.out_proj.bias', 'plm.layers.28.self_attn.rot_emb.inv_freq', 'plm.layers.28.self_attn_layer_norm.weight', 'plm.layers.28.self_attn_layer_norm.bias', 'plm.layers.28.fc1.weight', 'plm.layers.28.fc1.bias', 'plm.layers.28.fc2.weight', 'plm.layers.28.fc2.bias', 'plm.layers.28.final_layer_norm.weight', 'plm.layers.28.final_layer_norm.bias', 'plm.layers.29.self_attn.k_proj.weight', 'plm.layers.29.self_attn.k_proj.bias', 'plm.layers.29.self_attn.v_proj.weight', 'plm.layers.29.self_attn.v_proj.bias', 'plm.layers.29.self_attn.q_proj.weight', 'plm.layers.29.self_attn.q_proj.bias', 'plm.layers.29.self_attn.out_proj.weight', 'plm.layers.29.self_attn.out_proj.bias', 'plm.layers.29.self_attn.rot_emb.inv_freq', 'plm.layers.29.self_attn_layer_norm.weight', 'plm.layers.29.self_attn_layer_norm.bias', 'plm.layers.29.fc1.weight', 'plm.layers.29.fc1.bias', 'plm.layers.29.fc2.weight', 'plm.layers.29.fc2.bias', 'plm.layers.29.final_layer_norm.weight', 'plm.layers.29.final_layer_norm.bias', 'plm.layers.30.self_attn.k_proj.weight', 'plm.layers.30.self_attn.k_proj.bias', 'plm.layers.30.self_attn.v_proj.weight', 'plm.layers.30.self_attn.v_proj.bias', 'plm.layers.30.self_attn.q_proj.weight', 'plm.layers.30.self_attn.q_proj.bias', 'plm.layers.30.self_attn.out_proj.weight', 'plm.layers.30.self_attn.out_proj.bias', 'plm.layers.30.self_attn.rot_emb.inv_freq', 'plm.layers.30.self_attn_layer_norm.weight', 'plm.layers.30.self_attn_layer_norm.bias', 'plm.layers.30.fc1.weight', 'plm.layers.30.fc1.bias', 'plm.layers.30.fc2.weight', 'plm.layers.30.fc2.bias', 'plm.layers.30.final_layer_norm.weight', 'plm.layers.30.final_layer_norm.bias', 'plm.layers.31.self_attn.k_proj.weight', 'plm.layers.31.self_attn.k_proj.bias', 'plm.layers.31.self_attn.v_proj.weight', 'plm.layers.31.self_attn.v_proj.bias', 'plm.layers.31.self_attn.q_proj.weight', 'plm.layers.31.self_attn.q_proj.bias', 'plm.layers.31.self_attn.out_proj.weight', 'plm.layers.31.self_attn.out_proj.bias', 'plm.layers.31.self_attn.rot_emb.inv_freq', 'plm.layers.31.self_attn_layer_norm.weight', 'plm.layers.31.self_attn_layer_norm.bias', 'plm.layers.31.fc1.weight', 'plm.layers.31.fc1.bias', 'plm.layers.31.fc2.weight', 'plm.layers.31.fc2.bias', 'plm.layers.31.final_layer_norm.weight', 'plm.layers.31.final_layer_norm.bias', 'plm.layers.32.self_attn.k_proj.weight', 'plm.layers.32.self_attn.k_proj.bias', 'plm.layers.32.self_attn.v_proj.weight', 'plm.layers.32.self_attn.v_proj.bias', 'plm.layers.32.self_attn.q_proj.weight', 'plm.layers.32.self_attn.q_proj.bias', 'plm.layers.32.self_attn.out_proj.weight', 'plm.layers.32.self_attn.out_proj.bias', 'plm.layers.32.self_attn.rot_emb.inv_freq', 'plm.layers.32.self_attn_layer_norm.weight', 'plm.layers.32.self_attn_layer_norm.bias', 'plm.layers.32.fc1.weight', 'plm.layers.32.fc1.bias', 'plm.layers.32.fc2.weight', 'plm.layers.32.fc2.bias', 'plm.layers.32.final_layer_norm.weight', 'plm.layers.32.final_layer_norm.bias', 'plm.contact_head.regression.weight', 'plm.contact_head.regression.bias', 'plm.emb_layer_norm_after.weight', 'plm.emb_layer_norm_after.bias', 'plm.lm_head.weight', 'plm.lm_head.bias', 'plm.lm_head.dense.weight', 'plm.lm_head.dense.bias', 'plm.lm_head.layer_norm.weight', 'plm.lm_head.layer_norm.bias', 'protein_encoder.template_binding_site_enc.weight', 'pl_contact_stack.template_binding_site_enc.weight']\n",
      "  rank_zero_warn(\n",
      "/home/jupyter/google_cloud/protein_ligand/neuralPlexer/NeuralPLexer/neuralplexer/inference.py:650: UserWarning: Assuming the provided receptor input is a protein sequence\n",
      "  warnings.warn(\"Assuming the provided receptor input is a protein sequence\")\n",
      "[18:38:03] Warning: molecule is tagged as 2D, but at least one Z coordinate is not zero. Marking the mol as 3D.\n",
      "\n",
      "Block contact sampling:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Block contact sampling: 100%|██████████| 4/4 [00:00<00:00, 36.35it/s]\n",
      "Block contact sampling: 100%|██████████| 4/4 [00:00<00:00, 36.26it/s]\n",
      "\n",
      "Structure generation using langevin_simulated_annealing:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Structure generation using langevin_simulated_annealing:   2%|▎         | 1/40 [00:00<00:03,  9.83it/s]\n",
      "Structure generation using langevin_simulated_annealing:   5%|▌         | 2/40 [00:00<00:19,  1.98it/s]\n",
      "Structure generation using langevin_simulated_annealing:  10%|█         | 4/40 [00:01<00:08,  4.02it/s]\n",
      "Structure generation using langevin_simulated_annealing:  15%|█▌        | 6/40 [00:01<00:06,  5.65it/s]\n",
      "Structure generation using langevin_simulated_annealing:  20%|██        | 8/40 [00:01<00:04,  6.94it/s]\n",
      "Structure generation using langevin_simulated_annealing:  25%|██▌       | 10/40 [00:01<00:03,  7.92it/s]\n",
      "Structure generation using langevin_simulated_annealing:  28%|██▊       | 11/40 [00:01<00:03,  8.14it/s]\n",
      "Structure generation using langevin_simulated_annealing:  32%|███▎      | 13/40 [00:01<00:03,  8.88it/s]\n",
      "Structure generation using langevin_simulated_annealing:  38%|███▊      | 15/40 [00:02<00:02,  9.40it/s]\n",
      "Structure generation using langevin_simulated_annealing:  42%|████▎     | 17/40 [00:02<00:02,  9.73it/s]\n",
      "Structure generation using langevin_simulated_annealing:  48%|████▊     | 19/40 [00:02<00:02,  9.97it/s]\n",
      "Structure generation using langevin_simulated_annealing:  52%|█████▎    | 21/40 [00:02<00:01, 10.14it/s]\n",
      "Structure generation using langevin_simulated_annealing:  57%|█████▊    | 23/40 [00:02<00:01, 10.26it/s]\n",
      "Structure generation using langevin_simulated_annealing:  62%|██████▎   | 25/40 [00:03<00:01, 10.36it/s]\n",
      "Structure generation using langevin_simulated_annealing:  68%|██████▊   | 27/40 [00:03<00:01, 10.42it/s]\n",
      "Structure generation using langevin_simulated_annealing:  72%|███████▎  | 29/40 [00:03<00:01, 10.46it/s]\n",
      "Structure generation using langevin_simulated_annealing:  78%|███████▊  | 31/40 [00:03<00:00, 10.49it/s]\n",
      "Structure generation using langevin_simulated_annealing:  82%|████████▎ | 33/40 [00:03<00:00, 10.40it/s]\n",
      "Structure generation using langevin_simulated_annealing:  88%|████████▊ | 35/40 [00:04<00:00, 10.45it/s]\n",
      "Structure generation using langevin_simulated_annealing:  92%|█████████▎| 37/40 [00:04<00:00, 10.48it/s]\n",
      "Structure generation using langevin_simulated_annealing:  98%|█████████▊| 39/40 [00:04<00:00, 10.51it/s]\n",
      "Structure generation using langevin_simulated_annealing: 100%|██████████| 40/40 [00:04<00:00,  8.84it/s]\n",
      "/opt/conda/envs/prolig_0001/lib/python3.9/site-packages/pytorch3d/ops/points_alignment.py:340: UserWarning: Excessively low rank of cross-correlation between aligned point clouds. corresponding_points_alignment cannot return a unique rotation.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define variables for paths\n",
    "input_receptor_path = \"MGSSHHHHHHSSGLVPRGSHMAEVSHHWGYGKHNGPEHWHKDFPIANGERQSPVDIDTKAVVQDPALKPLALVYGEATSRRMVNNGHSFNVEYDDSQDKAVLKDGPLTGTYRLVQFHFHWGSSDDQGSEHTVDRKKYAAELHLVHWNTKYGDFGTAAQQPDGLAVVGVFLKVGDANPALQKVLDALDSIKTKGKSTDFPNFDPGSLLPNVLDYWTYPGSLTTPPLLESVTWIVLKEPISVSSQQMLKFRTLNFNAEGEPELLMLANWRPAQPLKNRQVRGFPK\"\n",
    "input_ligand_path = \"/home/jupyter/google_cloud/protein_ligand/neuralPlexer/bCa_co2/1v9e_C_ZN.sdf|/home/jupyter/google_cloud/protein_ligand/neuralPlexer/bCa_co2/h2o_ChEBI_15377.sdf|/home/jupyter/google_cloud/protein_ligand/neuralPlexer/bCa_co2/c02_ChEBI_16526.sdf\"\n",
    "out_path = \"/home/jupyter/google_cloud/protein_ligand/neuralPlexer/bCa_co2\"\n",
    "model_checkpoint_path = \"/home/jupyter/neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt\"\n",
    "\n",
    "command = [\n",
    "    \"neuralplexer-inference\",\n",
    "    \"--task=batched_structure_sampling\",\n",
    "    \"--input-receptor\", input_receptor_path,\n",
    "    \"--input-ligand\", input_ligand_path,\n",
    "    \"--out-path\", out_path,\n",
    "    \"--model-checkpoint\", model_checkpoint_path,\n",
    "    \"--n-samples\", \"1\",\n",
    "    \"--chunk-size\", \"1\",\n",
    "    \"--num-steps=40\",\n",
    "    \"--cuda\",\n",
    "    \"--sampler=langevin_simulated_annealing\"\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Print the stdout and stderr of the command\n",
    "print(\"STDOUT:\", result.stdout)\n",
    "print(\"STDERR:\", result.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-prolig_0001-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-env-prolig_0001-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
